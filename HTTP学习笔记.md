# 《HTTP权威指南》学习笔记




## URL

##### URI主要有两个子集： `URL` 和 `URN`

* URL通过资源位置来标识资源
* URN通过名字来识别资源

**PURL** 永久统一资源定位符，用URL来实现URN功能。


##### URL语法由 9 部分组成

``````
<scheme>://<user>:<password>@<host>:<port>/<path>;<params>?<query>#<frag>
``````

* `path` 分为多个路径段(path segment)，每个路径段都有自己的 `params` .
* `frag` 字段不会传送给服务器，由客户端内部使用。






## 报文

HTTP使用术语流入 `inbound` 和流出 `outbound` 来描述事务处理 `transaction` .

报文**发送者**总是位于**接收者**的上游(upstream)，所有报文都会向下游(downstream)流动。


#### 报文的语法

请求报文：

``````xml
<method> <request-URL> <version>
<headers>

<entity-body>
``````

响应报文:

``````xml
<version> <status> <reason-phrase>
<headers>

<entity-body>
``````

起始行和首部总是以 `CRLF` 结束。



#### 方法

常用HTTP方法： GET HEAD POST PUT TRACE OPTIONS DELETE.
由于HTTP设计得易于扩展，服务器还可以定义自己的`扩展方法`。

GET和HEAD被认为是 `安全方法` 。

###### GET

HTTP1.1 服务器必须实现此方法。用于请求服务器发送某个资源。

###### HEAD

HTTP1.1 服务器必须实现此方法。
与 `GET` 类似，但服务器在响应中只返回首部。开发者要确保其首部与GET返回的相同。

###### PUT

向服务器写入文档。

###### POST

向服务器输入数据。通常用来支持HTML表单。

###### TRACE

发起“环回”诊断，查看所有中间HTTP应用程序组成的链。主要用于诊断。

###### OPTIONS

请求Web服务器告知其支持的各种功能。

###### DELETE

删除请求URL所指定的资源。


###### 扩展方法

没有在HTTP1.1正式规范定义的方法。

最好按照惯例“对所发送的内容要求严一点，对所接收的内容宽松一点”来处理扩展方法。



#### 状态码

###### 分类：

| 整个范围    | 已定义范围   | 分类         |
| ----------- |:------------:|:------------ |
| 100 ~ 199   | 100 ~ 101    | 信息提示     |
| 200 ~ 299   | 200 ~ 206    | 成功         |
| 300 ~ 399   | 300 ~ 305    | 重定向       |
| 400 ~ 499   | 400 ~ 415    | 客户端错误   |
| 500 ~ 599   | 500 ~ 505    | 服务器错误   |

**100 Continue**：是一种优化，客户端在避免向服务器发送大实体时使用。
通常与 `Expect` 请求头配合使用，客户端在发送实体前等待100响应。

**204 No Content**: 响应报文包含若干首部和一个状态行，无实体的主体部分。
主要用于浏览器不转为新文档的情况下，对其进行更新。


> 302、303、307的区别

> `302` 在HTTP1.0时使用：客户端发出POST请求后收到服务器的302状态码，那么不能自动的向新的URI发送重复请求，
> 必须跟用户确认是否该重发(POST方法非幂等)。但是多数浏览器会获取到HTTP响应报文首部的Location字段信息，
> 并发起一个GET请求。

> `303` 在HTTP1.1中使用：大多数支持HTTP1.1的浏览器会将 302 当作 303 处理，其意义与 302 完全相同。

> `307` 在HTTP1.1中使用：用来代替 302 , 不会把POST转为GET.

> 也就是说， 302 由HTTP1.0细化为HTTP1.1中的 303 和 307.

**410 Gone**：与404类似，只是服务器曾拥有过此资源。



#### 首部

分类：

* 通用首部：可以出现在请求、响应报文中
* 请求首部
* 响应首部
* 实体首部
* 扩展首部








## 连接管理

#### Web浏览器通过TCP连接与Web服务器进行交互

一次请求过程：

1. 浏览器解析出主机名
2. 浏览器查询出主机名的IP地址
3. 浏览器获得端口号
4. 浏览器发起连接
5. 浏览器向服务器发起HTTP GET报文
6. 浏览器从服务器读取HTTP报文
7. 浏览器关闭连接

TCP数据是通过IP数据报的小数据块来发送的。

网络接口 -- IP -- TCP -- (TLS or SSL) -- HTTP

TCP通过 `端口号` 来保持连接的正确运行。

TCP连接通过4个值来唯一识别：

``````
源IP地址、 源端口号、 目的IP地址、 目的端口号
``````

TCP Socket通信：

![tcp socket](img/http_tcpsocket.png)



#### TCP 性能

HTTP事务时延主要原因：

1) 根据URI确定Web服务器IP和端口，DNS解析可能需要数10秒。(DNS缓存)

2) TCP连接建立时延通常有一两秒钟，HTTP事务多时会叠加

3) 网络传输报文及Web服务器从TCP连接中读取、处理报文都需要时间

4) Web服务器HTTP响应需要时间




#### HTTP 连接

提高HTTP连接性能的四类技术：

##### 一、并行连接

**1.并行连接可能会提高页面的加载速度。**

通过并行连接克服单条连接的空载时间和带宽限制。时延可以重叠，装载可并行。

**2.并行连接不一定更快**

带宽较小时，并行加载的多个对象会竞争有限的带宽，每个对象都会以较慢的速度加载；
打开大量连接会消耗内存资源，引发自身性能问题。

**3.并行连接可能让人感觉更快**

用户看到加载过程，整个页面多个对象同时加载。

##### 二、持久连接

> `站点本地性(site locality)` 初始化了对某服务器HTTP请求的应用程序，
很可能会在不久的将来对那台服务器发起更多的请求。

> `持久连接` 在事务处理结束之后仍然保持在打开状态的TCP连接。
它会在不同事务之间保持打开状态，由客户端或服务器主动关闭。

持久连接可以避开缓慢的连接建立阶段和TPC慢启动过程。

持久连接可能会累积大量空闲连接。可以与并行连接配合使用。

**Keep-Alive**

HTTP1.0的扩展，已不再使用，HTTP1.1规范中没有相关说明。但实际应用中仍广泛使用。

客户端请求头中包含 `Connection: Keep-Alive` 将连接保持打开状态，服务端响应同样的首部。
否则认为服务器不支持keep-alive, 客户端在发回响应报文后关闭连接。

Keep-Alive选项：

* `timeout` 估计了服务器希望保证连接的时间(并非承诺值)。
* `max` 估计了服务器还希望为多少个事务保持此连接(并非承诺值)。
* `name[=value]` 任意未经处理的属性，主要用于诊断和调试。

限制和规则：

* HTTP1.0中不是默认的，客户端必须显示发送相应首部。
* 响应报文中没有相应首部，代表服务器关闭连接。
* 持久连接实体的主体部分必须有正确的 `Content-Length`，有 `多部件媒体类型`，
或者用 `分块传输编码` 的方式进行编码。
* 代理或网关必须执行 Connection 首部的规则：将报文转发或高速缓存前，删除
Connection 首部中命名的所有首部字段以及 Connection 首部自身。
* 应忽略所有来自HTTP1.0的 Connect 首部


**哑代理**

> `blind relay` 盲中继：代理将字节从一个连接转发到另一个连接，不对Connection首部特殊处理。

代理和逐跳首部：Connection、Proxy-Authenticate、Proxy-Connenction、Transfer-Encoding、Upgrade



##### 三、管道化连接

在持久连接的基础上可选的使用 `请求管道`。在响应到达之前，将多条请求放入队列，降低网络环回时间。

服务器可以在任意时刻关闭一条TCP连接。

代理应该原封不动的转发包含错误Content-Length的请求，而不要试图纠正。

`幂等` 一个事务不管执行一次或是多次，结果都是相同的。GET、HEAD、PUT、DELETE、TRACE和OPTIONS都是幂等的。
客户端不应该以管道化方式传送非幂等操作，如POST。


##### 四、复用的连接

交替传送请求和响应报文(试验阶段)。


##### 关闭连接

TCP连接是双向的，每一端都有一个输入队列和一个输出队列。

套接字 `close()` 会将TCP输入和输出信道都关闭，称为 `完全关闭` 。
套接字 `shutdown()` 可以单独关闭输入或输出信道，称为 `半关闭` 。

关闭输出信道总是安全的。关闭输入信道比较危险，除非知道另一端不再发送其它数据。

将数据传送到已关闭的连接时会产生 `连接被对端重置` 错误。

无法确保对等实体会实现半关闭，或对其进行检查。因此想要正常关闭连接，应用程序应该先半关闭其输出信道，
然后周期性地检查其输入信道的状态。如果在一定的时间区间内对端没有关闭输入信道，应该程序可强行关闭连接。









## Web服务器

### 一、接受客户端连接

1. 处理新连接
2. 客户端主机名识别
3. 通过ident确定客户端用户

ident协议可以在组织内部使用，但不能在公共因特网上很好的工作。

### 二、接收请求报文

Web服务器输入输出结构：

* 单线程Web服务器
* 多进程及多线程Web服务器
* 复用IO的服务器
* 复用的多线程Web服务器

### 三、处理请求

### 四、对资源的映射及访问

Web服务器是资源服务器。

### 五、构建响应

响应报文通常包含 Content-Type、Content-Length和主体

MIME类型、魔法分类、显式分类、类型协商

### 六、发送响应

### 七、记录日志







##  代理


#### 代理是Web的中间实体

* `公共代理` 众多客户端共享的代理。(如，高速缓存代理服务器)
* `私有代理` 某个客户端专用或很多客户端共享。


* `代理` 连接的是两个或多个使用相同协议的应用程序。
* `网关` 连接的是两个或多个使用不同协议的端点。
* 实际上两者区别很模糊，很多代理服务器也实现网关的功能来支持SSL、FTP等。


**代理示例**

* 儿童过滤器(过滤黑名单)
* 文档访问控制(权限控制)
* 安全防火墙
* Web缓存
* 反向代理
* 内容路由器
* 转码器(图片压缩等)
* 匿名者

**常用部署方式**

* 出口代理：固定在本地网络的出口点
* 访问(入口)代理：ISP访问点上，处理客户聚合请求
* 反向代理：部署在网络边缘，Web服务器之前
* 网络交换代理：网络之间对等交换点上，通过缓存缓解拥塞

**代理层次结构**

`proxy hierarchy` 代理级联方式。
下一个入口(inbound)代理(靠近服务器)被称为`父代理`,
下一个出口(outbound)代理(靠近客户端)被称为`子代理`。

代理层次结构可以是动态的，随请求而变。

动态选择父代理示例：

* 负载均衡
* 地理位置附近的路由
* 协议/类型路由
* 基于订购的路由


**Web请求导向代理的方法**

* 修改客户端
* 修改网络( `拦截代理` )
* 修改DNS的命名空间
* 修改Web服务器(305重定向等)

**Via首部**

Via列出了报文经过的中间节点，报文每经过一个节点都必须将该节点添加到Via列表的尾部。

代理也可以通过Via首部来检测路由循环。

`waypoint` 路标：Via首部中表示一个独立的代理服务器或网关，由逗号分隔。

每个Via路标最多包含四个组件：

1. 可选的协议名(默认HTTP)
2. 必选的协议版本
3. 必选的节点名：主机+端口(如果无端口，使用协议默认端口)
4. 可选的描述性注释

请求和响应报文中都有Via首部，且通常相反。

`Server` 首部用来描述原始服务器使用的软件，代理一定不能修改 Server 首部。

Via的隐私和安全问题：可能暴露防火墙后的主机名、端口和网络结构。
可以通过隐藏主机名或压缩合并多个路标解决。

TRACE方法可以用来追踪调试代理流，但它还没有得到广泛实现。
`Max-Forwards` 可以用来限制最大的代理跳数。

**代理认证**

> HTTP/1.0 407 Proxy Authorization Required

> Proxy-Authenticate: Basic realm="Secure Stuff"

1. 代理服务器对受限请求返回407及Proxy-Authenticate响应报文；
2. 客户端从本地数据库或提示用户搜集所需要的证书；
3. 客户端重发请求，在Proxy-Authorization首部提供所要求的证书；
4. 证书有效则代理将原始请求沿传输链路向下传送，否则返回另一条407应答；

链路中有多个需要认证的代理时，不能很好的工作。HTTP升级目前没有广泛实现。

**代理的互操作性**

使用OPTIONS方法判定服务器支持的方法。

HTTP1.1中使用 `Allow` 首部响应服务器所支持的方法。例如：

``````
Allow: GET, HEAD, PUT
``````








## 缓存


#### 缓存的作用

* **冗余的数据传输**：一份文档多次传输变为缓存副本。
* **带宽瓶颈**：客户端会以路径上最慢的网速访问服务器。可在客户端局域网中缓存副本提升速度。
* **瞬间拥塞**：缓存在破坏瞬间拥塞(Flash Crowds)时显得非常重要。
* **距离时延**：将缓存放在附近的机房。

#### 缓存命中

`cache hit` 缓存命中：用已有的副本为某些到达缓存的请求提供服务。

`cache miss` 缓存未命中：一些到达缓存的请求由于没有副本可用，而被转发给原始服务器。

`revalidation` 再验证：原始服务器的内容可能发生变化，缓存要不时检测其副本是否是服务器上最新的副本。

`revalidation hit` 再验证命中(或 `slow hit` 缓慢命中)：缓存对其副本进行再验证时，
会向原始服务器发起一个小的再验证请求，如果服务器返回304缓存再次将副本标识为新鲜的。
缓慢命中要比缓存命中慢，比缓存未命中快。使用 `If-Modified-Since` 首部进行再验证。

**命中率**

`缓存命中率` ：由缓存提供服务的请求所占的比例。对现在中等规模的缓存，40%的命中率是合理的。

`字节命中率` ：缓存提供的字节在传输的所有字节中所占的比例。

客户端可以使用 `Date` 首部或 `Age` 首部来检测缓存响应。

#### 缓存的拓扑结构

私有缓存：一般Web浏览器中会内建私有缓存。

公有缓存：缓存代理服务器。

层次结构：一级、二级...缓存；网状缓存、内容路由、对等缓存。

#### 缓存的处理步骤

1. 接收：从网络中读取抵达的请求报文；
2. 解析：对报文进行解析，提取出URL和各种首部；
3. 查询：查看是否有本地副本可用，如果没有就获取一份副本并保存至本地；
4. 新鲜度检测：查看已缓存副本是否足够新鲜，如果不是，就询问服务器是否有任何更新；
5. 创建响应：用新的首部和已缓存的主体构建一条响应报文；
6. 发送：通过网络将响应发送给客户端；
7. 日志：可选的创建一个日志文件条目来记录此事务。

#### 保持副本新鲜

缓存 GET 请求的流程图：

![GET CACHE](img/http_cache_getcache.png)

__过期日期__

`Expires` ：响应首部用来指定一个绝对日期表示过期日期。超过此日期则说明文档不再新鲜。

`Cache-Control: max-age` ：定义文档的最大合法生存时间(以秒为单位)。

__再验证__

> HTTP 定义的 5 个条件首部：

> `If-Modified-Since` ：通过比较过期日期进行再验证。

> `If-None-Match` ：通过比较实体标签(ETag)进行再验证。

> `If-Unmodified-Since` ：在进行部分文件的传输时，获取文件的其余部分之前用来确保文件未发生变化。

> `If-Range` ：支持对不完整文档的缓存。

> `If-Match` ：用于与Web服务器打交道时的并发控制。

IMS请求：`If-Modified-Since` 再验证请求。只有自某个日期之后资源发生了变化的时候，
IMS请求才会执行：返回新文档给缓存或304，以及新的过期日期。
有些Web服务器只是将IMS日期和文档最后修改日期进行字符串比较。

强弱验证器：只要内容发生变化，强验证器就会变化；内容的主要含义发生变化时，弱验证器会变化。
服务器会用 `W/` 前缀来标识弱验证器。

``````
ETag: W/"v2.6"
If-None-Match: W/"v2.6"
``````

如果服务器回送了一个 `ETag` ，HTTP1.1客户端就必须使用实体标签验证器。
如果服务器只回送一个 `Last-Modified` 值，客户端就可以使用 `If-Modified-Since` 验证。
如果两种方式都提供，客户端应该使用两种再验证方式。


#### 控制缓存

`Cache-Control: no-store` ：禁止缓存对响应进行复制。缓存会像非缓存代理服务器一样，
像客户端发送一条 no-store 响应，然后删除对象。

`Cache-Control: no-cache` ：响应可以存储在本地缓存区中。
只是在与原始服务器进行新鲜度再验证之前，缓存不能将其提供给客户端使用。

`Pragma: no-cache` ：兼容HTTP1.0+

`Cache-Control: max-age` ：从服务器将文档传来之时起，
可以认为此文档处于新鲜状态的秒数。 `s-maxage` 表示仅适用于公有缓存。

``````
Cache-Control: max-age=3600
Cache-Control: s-maxage=3600
``````

服务器可以将最大使用期设置为 0 ，从而在每次访问时都刷新。

`Expires` ：(不推荐使用) 指定实际的过期日期。HTTP设计者后来认为服务器时钟不同步或不正确，
所以最好还是使用剩余秒数来表示过期时间。

`Cache-Control: must-revalidate` ：缓存在事先没有跟原始服务器进行再验证的情况下，
不能提供对象的陈旧副本。如果缓存进行新鲜度检查时原始服务器不可用，缓存必须返回**504**错误。

`试探性过期` ：缓存可以计算出一个试探性最大使用期。*LM-Factor算法*


##### Cache-Control

| 指令                           | 目的                                               |
|:------------------------------ |:-------------------------------------------------- |
| Cache-Control: max-stale       | 缓存可以随意提供过期文件(放松缓存规则)             |
| Cache-Control: max-stale=s     | 在时间 s 秒内，文档不能过期                        |
| Cache-Control: min-fresh=s     | 至少在未来 s 秒内文档要保持新鲜(严格规则)          |
| Cache-Control: max-age=s       | 缓存无法返回缓存时间长于 s 秒的文档(严格规则)      |
| Cache-Control: no-cache        | 除非资源进行了再验证，否则客户端不接受已缓存的资源 |
| Pragma: no-cache               | HTTP/1.0+ 同上                                     |
| Cache-Control: no-store        | 缓存应该尽快从存储器中删除文档的所有痕迹           |
| Cache-Control: only-if-cached  | 只有当缓存中有副本存在时，客户端才会获取一份副本   |









## 集成点


### 网关

`gateway` 抽象出了一种能够到达资源的方法，是资源和应用程序之间的粘合剂。

Web网关在一侧使用HTTP协议，另一侧使用另一种协议：

``````xml
<客户端协议>/<服务器端协议>
``````

例如: `HTTP/NNTP`

__协议网关__

HTTP/*、 HTTP/HTTPS、 HTTPS/HTTP(安全加速器网关)

__资源网关__

CGI(通用网关接口)、扩展API(RPC等)

__Web Service__

Web应用程序之间相互通信的标准和协议，用XML通过SOAP来交换信息。


### 隧道

通过CONNECT方法请求隧道网关创建一条到达任意目的服务器和端口的TCP连接，
并对客户端和服务器之间的后继数据进行盲转发。

__CONNECT请求__

``````
CONNECT home.netscape.com:443 HTTP/1.0
User-Agent: Mozilla/4.0
``````

和其它HTTP方法类似，只是URI变成 `host:port` 形式。

__CONNECT响应__

``````
HTTP/1.0 200 Connection Established
Proxy-Agent: Netscape-Proxy/1.1
``````

响应中不需要包含 `Content-Type` .

__SSL隧道__

将原始的加密数据放在HTTP报文中，通过普通的HTTP信道传送。

### 中继

`relay` 是没有完全遵循HTTP规范的简单HTTP代理。
中继负责处理HTTP中建立连接的部分，然后对字节进行盲转发。

由于中继无法正确处理 `Connection` 首部，所以有潜在的挂起 `keep-alive` 连接的可能。











## Web机器人


### 爬虫

`根集(root set)` ：爬虫开始访问的初始URL集合。

通常一个好的根集会包括一些在的流行Web站点、一个新创建页面的列表和一个不经常被链接的无名页面列表。

机器人必须知道它们到过何处，避免环路的出现。

__面包屑痕迹__

管理访问过的地址的技术：

* 树和散列表
* 有损的存在位图
* 检查点：已访问URL列表保存到硬盘，以防机器人崩溃
* 分类：机器人集群

Web机器人通过规范化URL来消除URL别名(不同URL指向同一文档)。

__爬虫陷阱__

* 文件系统连接环路：在目录层次深度有限的情况下，造成深度无限的假象。
* 动态虚拟Web空间：发布看起来像普通文件，实际上却是网关应用程序的URL。
应用程序在传输中构造出包含了到同一服务器上虚构URL链接的HTML。

__避免循环__

* 规范化URL
* 广度优先的爬行
* 节流：限制一段时间内机器人在同一Web站点获取的页面数量
* 限制URL的大小：拒绝超出长度的URL(通过是1KB)
* URL/站点黑名单
* 模式检测：URL组件重复出现等(/subdir/imgs/subdir/imgs/subdir/imgs...)
* 内容指纹：采用MD5等进行指纹计算，为每个页面内容计算 `校验和(checksum)`
* 人工监视：诊断和日志功能


### 机器人HTTP

1) 识别首部(鼓励机器人使用)：

* `User-Agent` 将发起请求的机器人名称告知服务器
* `From` 提供机器人的用户/管理者的E-mail(RFC 822)
* `Accept` 告知服务器发送哪些媒体类型
* `Referer` 提供包含了当前请求URL的文档的URL

2) 虚拟主机

机器人的实现者要支持 `Host` 首部，避免虚拟主机引发问题。

3) 条件请求

通过条件HTTP请求，只在内容发生变化时才重新获取内容。

4) 对响应的处理

能够识别 `200` 、 `404` 等常见的状态码；在实体中查找一些有用信息(如元标签http-equiv)

5) User-Agent导向

站点管理者应该设计一个处理机器人请求的策略。


### 行为不当的机器人

* 失控机器人：造成Web服务过载
* 失效的URL：大量请求不存在的URL，造成服务器日志冗余等
* 很长的错误URL：过长的URL造成Web服务器性能降低、日志杂乱甚至崩溃
* 爱打听的机器人：机器人跟踪Web服务器不愿意发布的敏感文档
* 动态网关访问

### 拒绝机器人访问

拒绝机器人访问标准： `robots.txt` .
在服务器文档根目录提供可选的*robots.txt*文件。

__robots.txt文件格式__

1) User-Agent 行

``````
User-Agent: <robot-name>
或
User-Agent: *
``````

机器人名是与大小写无关的子字符串进行匹配。
如 bot 与 Bot、Robot、Bottom-Feeder、SpamBot 等所有机器人匹配。

2) Disallow 和 Allow 行

紧跟UA行后，用来说明禁止/允许访问的URL路径。










## HTTPS

在HTTP应用层与TCP传输层之间增加安全层，通过 `SSL` 或 `TLS` 协议来实现。

SSL 是二进制协议，通过由端口 `443` 承载。

__SSL握手__

发送加密报文前，客户端和服务器进行一次SSL握手：

* 交换协议版本号
* 选择一个两端都了解的密码
* 对两端的身份进行认证
* 生成临时的会话密钥，以便加密信道

简化版SSL握手：

![SSL握手](img/http_https_ssl.png)

__ 服务器证书__

SSL支持双向认证，但浏览器并不经常使用客户端证书。

> 安全HTTPS事务总是要求使用服务器证书的。

证书的有效性验证算法：

1. 日期检测：确保证书未过期并激活
2. 签名颁发者可信度检测：浏览器中保存受信CA列表
3. 签名检测：使用公开密钥与校验码比较
4. 站点身份检测：验证证书中的域名和服务器域名是否匹配

__HTTPS SSL隧道协议__

客户端在开始加密前以明文的方式告诉代理目标主机和端口。












